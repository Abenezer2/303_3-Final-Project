{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ca6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fbba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
    "data.columns = [x.strip() for x in data.columns.tolist()]\n",
    "X = data.drop(columns = ['url', 'shares', 'timedelta', 'weekday_is_monday', 'weekday_is_saturday', 'LDA_00', 'n_unique_tokens',\n",
    " 'n_non_stop_words','self_reference_avg_sharess','rate_positive_words','global_subjectivity','avg_positive_polarity','LDA_01',\n",
    " 'LDA_04','LDA_02','kw_max_max','kw_avg_max','kw_avg_min','kw_max_avg','is_weekend','global_rate_positive_words','rate_negative_words',\n",
    " 'min_negative_polarity','max_negative_polarity','abs_title_sentiment_polarity'])\n",
    "y = data['shares']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b222b",
   "metadata": {},
   "source": [
    "# We will start tuning parameters one by one to look for a general range to look for, for when we tune all the parameters at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffda85e",
   "metadata": {},
   "source": [
    "### Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5 3.332 (0.034)\n",
      ">10 1.871 (0.013)\n",
      ">50 1.894 (0.009)\n",
      ">100 1.910 (0.007)\n",
      ">500 1.965 (0.011)\n",
      ">1000 1.982 (0.013)\n",
      ">2000 1.989 (0.014)\n"
     ]
    }
   ],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    # define number of trees to consider\n",
    "    n_trees = [5, 10, 50, 100, 500, 1000, 2000, 5000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = xgb.XGBRegressor(n_estimators=n,random_state=1)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = -cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_train, np.log(y_train))\n",
    "    scores = np.exp(scores)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('Cross validation error',fontsize=15)\n",
    "plt.xlabel('Number of trees',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e07489",
   "metadata": {},
   "source": [
    "### Depth of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # explore depths from 1 to 10\n",
    "    for i in range(1,21):\n",
    "        # define ensemble model\n",
    "        models[str(i)] = xgb.XGBRegressor(random_state=1,max_depth=i)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = -cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_train, np.log(y_train))\n",
    "    scores = np.exp(scores)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('Cross validation error',fontsize=15)\n",
    "plt.xlabel('Depth of each tree',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaaae0",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    # explore learning rates from 0.1 to 2 in 0.1 increments\n",
    "    for i in [0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.8,1.0]:\n",
    "        key = '%.4f' % i\n",
    "        models[key] = xgb.XGBRegressor(learning_rate=i,random_state=1)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = -cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_train, np.log(y_train))\n",
    "    scores = np.exp(scores)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.1f (%.1f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('Cross validation error',fontsize=15)\n",
    "plt.xlabel('Learning rate',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41439a6f",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ee1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    # explore learning rates from 0.1 to 2 in 0.1 increments\n",
    "    for i in [0,0.5,1.0,1.5,2,10,100]:\n",
    "        key = '%.4f' % i\n",
    "        models[key] = xgb.XGBRegressor(reg_lambda=i,random_state=1)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = np.sqrt(-cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.1f (%.1f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('Cross validation error',fontsize=15)\n",
    "plt.xlabel('reg_lambda',fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
